{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62037f37",
   "metadata": {
    "papermill": {
     "duration": 0.006154,
     "end_time": "2023-11-26T19:51:20.962352",
     "exception": false,
     "start_time": "2023-11-26T19:51:20.956198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Project Part 2\n",
    "\n",
    "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/brearenee/NLP-Project/blob/main/part2-startrek.ipynb)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgeinitz/https://github.com/brearenee/NLP-Project/blob/main/part2-startrek.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2ae2b2",
   "metadata": {
    "papermill": {
     "duration": 0.00535,
     "end_time": "2023-11-26T19:51:20.975534",
     "exception": false,
     "start_time": "2023-11-26T19:51:20.970184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**NLP Problem:** given a script from Star Trek The Next Generation, predict from 8 main characters who said a line. \n",
    "\n",
    "Part 2 of my project involves creating a basic model for my NLP problem\n",
    "\n",
    "\n",
    "As mentioned in Part 1, my dataset's original format is not in the most useful form.  \n",
    "To start Part 2, I must parse through the raw JSON and return an organized dataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96fee2e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T19:51:20.988823Z",
     "iopub.status.busy": "2023-11-26T19:51:20.988431Z",
     "iopub.status.idle": "2023-11-26T19:51:23.298248Z",
     "shell.execute_reply": "2023-11-26T19:51:23.296809Z"
    },
    "papermill": {
     "duration": 2.320467,
     "end_time": "2023-11-26T19:51:23.301619",
     "exception": false,
     "start_time": "2023-11-26T19:51:20.981152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87b68e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T19:51:23.316221Z",
     "iopub.status.busy": "2023-11-26T19:51:23.315538Z",
     "iopub.status.idle": "2023-11-26T19:51:26.416203Z",
     "shell.execute_reply": "2023-11-26T19:51:26.414994Z"
    },
    "papermill": {
     "duration": 3.110927,
     "end_time": "2023-11-26T19:51:26.419115",
     "exception": false,
     "start_time": "2023-11-26T19:51:23.308188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/brearenee/NLP-Project/main/dataset/StarTrekDialogue_v2.json'\n",
    "response = requests.get(url)\n",
    "\n",
    "##This CodeBlock is thanks to ChatGPT :-) \n",
    "if response.status_code == 200:\n",
    "    json_data = json.loads(response.text)\n",
    "    lines = []\n",
    "    characters = []\n",
    "    episodes = []\n",
    "  \n",
    "    # extract the information from the JSON file for the \"TNG\" series\n",
    "    for series_name, series_data in json_data.items():\n",
    "        if series_name == \"TNG\": \n",
    "            for episode_name, episode_data in series_data.items():\n",
    "                for character_name, character_lines in episode_data.items():\n",
    "                    for line_text in character_lines:\n",
    "                        lines.append(line_text)\n",
    "                        characters.append(character_name)\n",
    "                        episodes.append(episode_name)\n",
    "                     \n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame({\n",
    "        'Line': lines,\n",
    "        'Character': characters,\n",
    "        'Episode': episodes,\n",
    "    })\n",
    "\n",
    "    # Remove duplicate lines, keeping the first occurrence (preserving the original order)\n",
    "    df = df.drop_duplicates(subset='Line', keep='first')\n",
    "\n",
    "    # Reset the index of the DataFrame\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd2639",
   "metadata": {
    "papermill": {
     "duration": 0.005563,
     "end_time": "2023-11-26T19:51:26.430613",
     "exception": false,
     "start_time": "2023-11-26T19:51:26.425050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We then need to clean our dataset by removing non-main characters.  We are going to remove all characters that have less than 1000 lines. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ebc8fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T19:51:26.444386Z",
     "iopub.status.busy": "2023-11-26T19:51:26.443966Z",
     "iopub.status.idle": "2023-11-26T19:51:26.471472Z",
     "shell.execute_reply": "2023-11-26T19:51:26.470244Z"
    },
    "papermill": {
     "duration": 0.038301,
     "end_time": "2023-11-26T19:51:26.474749",
     "exception": false,
     "start_time": "2023-11-26T19:51:26.436448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "character_counts = df['Character'].value_counts()\n",
    "\n",
    "characters_to_remove = character_counts[character_counts < 1000].index\n",
    "df = df[~df['Character'].isin(characters_to_remove)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35c8c15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T19:51:26.488704Z",
     "iopub.status.busy": "2023-11-26T19:51:26.487569Z",
     "iopub.status.idle": "2023-11-26T19:51:26.503249Z",
     "shell.execute_reply": "2023-11-26T19:51:26.502087Z"
    },
    "papermill": {
     "duration": 0.025697,
     "end_time": "2023-11-26T19:51:26.506268",
     "exception": false,
     "start_time": "2023-11-26T19:51:26.480571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Character\n",
       "PICARD     10798\n",
       "RIKER       6454\n",
       "DATA        5699\n",
       "LAFORGE     4111\n",
       "WORF        3185\n",
       "CRUSHER     2944\n",
       "TROI        2856\n",
       "WESLEY      1206\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Character'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8785ffbd",
   "metadata": {
    "papermill": {
     "duration": 0.005645,
     "end_time": "2023-11-26T19:51:26.517946",
     "exception": false,
     "start_time": "2023-11-26T19:51:26.512301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Decision Tree\n",
    "For my simple model, I'll be using a Decision Tree Classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9031af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T19:51:26.533087Z",
     "iopub.status.busy": "2023-11-26T19:51:26.531923Z",
     "iopub.status.idle": "2023-11-26T19:51:27.333479Z",
     "shell.execute_reply": "2023-11-26T19:51:27.332077Z"
    },
    "papermill": {
     "duration": 0.812587,
     "end_time": "2023-11-26T19:51:27.336754",
     "exception": false,
     "start_time": "2023-11-26T19:51:26.524167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorize the \"Line\" column using a \"bag of words\" representation.  \n",
    "# This represntation converts the lines of text into a numerical format \n",
    "# that can be used by the DecisionTreeClassifier for prediction.\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "#extract the lines from my dataframe\n",
    "lines = df['Line'].tolist()\n",
    "character = df['Character'].tolist()\n",
    "\n",
    "X = vectorizer.fit_transform(lines)\n",
    "y = character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1337a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T19:51:27.352114Z",
     "iopub.status.busy": "2023-11-26T19:51:27.350597Z",
     "iopub.status.idle": "2023-11-26T19:51:41.820864Z",
     "shell.execute_reply": "2023-11-26T19:51:41.819431Z"
    },
    "papermill": {
     "duration": 14.480609,
     "end_time": "2023-11-26T19:51:41.823808",
     "exception": false,
     "start_time": "2023-11-26T19:51:27.343199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3206281036102537\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Decision Tree model\n",
    "model1 = DecisionTreeClassifier(\n",
    "    random_state=42)\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set and evaluate the model\n",
    "y_pred = model1.predict(X_test)\n",
    "accuracy1 = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f650b",
   "metadata": {
    "papermill": {
     "duration": 0.005622,
     "end_time": "2023-11-26T19:51:41.835629",
     "exception": false,
     "start_time": "2023-11-26T19:51:41.830007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As you can see, the model's accuracy is terrible. Lets adjust some hyper parameters to try and increase the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6987b5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T19:51:41.850140Z",
     "iopub.status.busy": "2023-11-26T19:51:41.848844Z",
     "iopub.status.idle": "2023-11-26T19:51:43.946725Z",
     "shell.execute_reply": "2023-11-26T19:51:43.945540Z"
    },
    "papermill": {
     "duration": 2.107522,
     "end_time": "2023-11-26T19:51:43.949080",
     "exception": false,
     "start_time": "2023-11-26T19:51:41.841558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3482753992752651\n"
     ]
    }
   ],
   "source": [
    "model2 = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=20, \n",
    "    #min_samples_split=5,  \n",
    "    #min_samples_leaf=1,  \n",
    "    #max_features='sqrt',  \n",
    "    #criterion='entropy' \n",
    ")\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set and evaluate the model\n",
    "y_pred = model2.predict(X_test)\n",
    "accuracy2 = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ac3a2",
   "metadata": {
    "papermill": {
     "duration": 0.005805,
     "end_time": "2023-11-26T19:51:43.960897",
     "exception": false,
     "start_time": "2023-11-26T19:51:43.955092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After trial and error with many different hyper parameters,  I realized these arent going to help much.  I'm going to try a different approach - instead of a Bag of Words type representation, I'm going to try TF-IDF to represent the text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb22699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T19:51:43.975490Z",
     "iopub.status.busy": "2023-11-26T19:51:43.974597Z",
     "iopub.status.idle": "2023-11-26T19:51:47.453847Z",
     "shell.execute_reply": "2023-11-26T19:51:47.452497Z"
    },
    "papermill": {
     "duration": 3.489433,
     "end_time": "2023-11-26T19:51:47.456498",
     "exception": false,
     "start_time": "2023-11-26T19:51:43.967065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34223594148436454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#TF-IDF vecotorization instead of Bag of Words. \n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(lines)\n",
    "y = character\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Adjust hyperparameters (you can experiment with these)\n",
    "model3 = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    #min_samples_leaf=2,\n",
    "    #max_features='sqrt',\n",
    "    #criterion='gini'\n",
    ")\n",
    "\n",
    "\n",
    "model3.fit(X_train, y_train)\n",
    "y_pred = model3.predict(X_test)\n",
    "accuracy3 = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed961b69",
   "metadata": {
    "papermill": {
     "duration": 0.005987,
     "end_time": "2023-11-26T19:51:47.469266",
     "exception": false,
     "start_time": "2023-11-26T19:51:47.463279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Switching from bag of words to TF-IDF didn't change much. In fact, The accuracy went slightly down. Next we are going to try a different model, but sticking with TF-IDF\n",
    "\n",
    "\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f654489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T19:51:47.483727Z",
     "iopub.status.busy": "2023-11-26T19:51:47.483272Z",
     "iopub.status.idle": "2023-11-26T19:54:13.546846Z",
     "shell.execute_reply": "2023-11-26T19:54:13.545621Z"
    },
    "papermill": {
     "duration": 146.080115,
     "end_time": "2023-11-26T19:54:13.555603",
     "exception": false,
     "start_time": "2023-11-26T19:51:47.475488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41068312978123744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model4 = RandomForestClassifier(random_state=42)\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model4.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy4 = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7acd3",
   "metadata": {
    "papermill": {
     "duration": 0.00591,
     "end_time": "2023-11-26T19:54:13.567762",
     "exception": false,
     "start_time": "2023-11-26T19:54:13.561852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It's better! 41% still doesn't seem too accurate, but considering there are 8 possible classifications, it's better than a normal guess. "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 176.850665,
   "end_time": "2023-11-26T19:54:14.295606",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-26T19:51:17.444941",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
